{
  "address": "0x4fa28f05a4f2dee638823fb625c7aabe2ccc68b0",
  "chat": "https://huggingface.co/second-state/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf",
  "chat_batch_size": "128",
  "chat_ctx_size": "16384",
  "chat_name": "Llama-3.2-3B-Instruct",
  "chat_ubatch_size": "128",
  "context_window": 1,
  "description": "The default GaiaNet node config with a Llama-3.2-3B-Instruct model.",
  "domain": "gaia.domains",
  "embedding": "https://huggingface.co/gaianet/Nomic-embed-text-v1.5-Embedding-GGUF/resolve/main/nomic-embed-text-v1.5.f16.gguf",
  "embedding_batch_size": "8192",
  "embedding_collection_name": "default",
  "embedding_ctx_size": "8192",
  "embedding_name": "Nomic-embed-text-v1.5",
  "embedding_ubatch_size": "8192",
  "llamaedge_chat_port": "9068",
  "llamaedge_embedding_port": "9069",
  "llamaedge_port": "8081",
  "prompt_template": "llama-3-chat",
  "qdrant_limit": "3",
  "qdrant_score_threshold": "0.5",
  "qdrant_url": "http://localhost:6333",
  "rag_policy": "system-message",
  "rag_prompt": "Use the following information to answer the question.",
  "reverse_prompt": "",
  "snapshot": "shared_knowledge_base",
  "system_prompt": "You are a helpful AI assistant. Please answer questions as clearly and concisely as possible."
}